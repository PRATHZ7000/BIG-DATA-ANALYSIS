# -*- coding: utf-8 -*-
"""Prathamesh Murkute Task 1 BIG DATA ANALYSIS .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dTc5IKOgmuizuM5ik4ZndREROOlVsHAz
"""

pip install pyspark

from pyspark.sql import SparkSession

# Initialize Spark Session
spark = SparkSession.builder \
    .appName("Big Data Analysis - College Data") \
    .getOrCreate()

df = spark.read.csv("/content/drive/MyDrive/task data set/College.csv", header=True, inferSchema=True)

# Show first few rows
df.show(5)

df.printSchema()

# Count rows
print("Total Records:", df.count())

from pyspark.sql.functions import col

# Rename columns with periods
df = df.withColumnRenamed("F.Undergrad", "F_Undergrad") \
       .withColumnRenamed("P.Undergrad", "P_Undergrad") \
       .withColumnRenamed("Room.Board", "Room_Board") \
       .withColumnRenamed("S.F.Ratio", "S_F_Ratio") \
       .withColumnRenamed("perc.alumni", "perc_alumni") \
       .withColumnRenamed("Grad.Rate", "Grad_Rate")

# Now apply dropna and dropDuplicates
df = df.dropna()

# Remove duplicates
df = df.dropDuplicates()

from pyspark.sql.functions import col, when

# Example: Convert 'Private' column to binary
df = df.withColumn("Private_Binary", when(col("Private") == "Yes", 1).otherwise(0))

df.groupBy("Private").avg("Outstate").show()

df.select("Apps", "Accept").summary("mean", "stddev", "min", "max").show()

df.orderBy(col("Grad_Rate").desc()).select("_c0", "Grad_Rate").show(10)

print("Number of partitions:", df.rdd.getNumPartitions())

# Repartition if needed (e.g., for distributed performance)
df = df.repartition(4)

sample_df = df.sample(fraction=0.1).toPandas()

import matplotlib.pyplot as plt
import seaborn as sns

sns.scatterplot(x='Apps', y='Accept', data=sample_df)
plt.show()